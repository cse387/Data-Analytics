{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear search results:\n",
      "Number of NN with dist < r:  453\n",
      "LSH results:\n",
      "Number of NN with dist < r:  354\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import findspark\n",
    "findspark.init()\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from functools import reduce\n",
    "from pyspark import SparkContext,SparkConf,AccumulatorParam\n",
    "conf=SparkConf()\n",
    "sc = SparkContext(conf=conf ,master=\"local[*]\")\n",
    "#LSH-(r,cr,k,m) Family \n",
    "n=2**10\n",
    "d=2**7\n",
    "r=d/2\n",
    "c=3/2\n",
    "k=int(math.log(n,2)/2)\n",
    "m=50\n",
    "band=50\n",
    "\n",
    "class ListAccumulatorParam(AccumulatorParam):\n",
    "    def zero(self, initialValue):\n",
    "        return initialValue\n",
    "    def addInPlace(self, v1, v2):\n",
    "        v1.append(v2)\n",
    "        return v1\n",
    "\n",
    "data=[[rn.randint(0,1) for i in range(d)] for j in range(n)]\n",
    "\n",
    "query=[rn.randint(0,1) for i in range(d)]\n",
    "\n",
    "def bin_to_dec(Bin):\n",
    "    s=0\n",
    "    for i in range(len(Bin)):\n",
    "        if Bin[i]!=0:\n",
    "            s+=2**i\n",
    "    return s\n",
    "    \n",
    "def reduce_(x,y):\n",
    "    s=[]\n",
    "    for i in zip(x,y):\n",
    "        s.append(i[0]+i[1])\n",
    "    return s\n",
    "\n",
    "H_Family=[i for i in range(k)]\n",
    "\n",
    "def H(x,i):\n",
    "    return x[i]\n",
    "\n",
    "def create_Signatures(x,H_Family):\n",
    "    Hashed_Data=[]\n",
    "    H_Family=rn.sample(H_Family,k)\n",
    "    Hashed_Row=[]\n",
    "    for item in x:\n",
    "        #H_Family=rn.sample(H_Family,k)\n",
    "        Hashed_Row.append([H(item,j) for j in H_Family])\n",
    "    return Hashed_Row\n",
    "try:\n",
    "\n",
    "    signatures=sc.parallelize([data for i in range(m)]).map(lambda x:create_Signatures(x,H_Family))\n",
    "\n",
    "    def partitioning_To_Bands(Sign_Data):#partition the Rdd\n",
    "        if band==m:\n",
    "            return Sign_Data\n",
    "        else:\n",
    "            bands=[]\n",
    "            size=m//band\n",
    "            for i in range(0,len(Sign_Data),size):\n",
    "                reduced_Data=reduce(lambda x,y:reduce_(x,y),Sign_Data[i:i+size])\n",
    "                bands.append(reduced_Data)\n",
    "            return bands\n",
    "\n",
    "    Tables=sc.accumulator(list(), ListAccumulatorParam())\n",
    "    #Sign_Data=partitioning_To_Bands(signatures.collect())\n",
    "\n",
    "    def Hash_To_Buckets(row):\n",
    "        Bucket={}\n",
    "        for i in range(len(row)):\n",
    "            key=bin_to_dec(row[i])\n",
    "            if key not in Bucket.keys():\n",
    "                Bucket[key]=[data[i]]\n",
    "            elif data[i] not in Bucket[key]:\n",
    "                Bucket[key]+=[data[i]]\n",
    "        Tables.add(Bucket)\n",
    "    signatures.foreach(Hash_To_Buckets)\n",
    "    #sc.parallelize(Sign_Data).foreach(Hash_To_Buckets)  \n",
    "    def Nearest_Neighbors(bucket,query,r):\n",
    "        NN=[]\n",
    "        global H_Family\n",
    "        H_Family=rn.sample(H_Family,k)\n",
    "        query_key=bin_to_dec([H(query,j) for j in H_Family])\n",
    "        if query_key in bucket.keys():\n",
    "            NN=[]\n",
    "            neighs=bucket[query_key]\n",
    "            for neigh in neighs:\n",
    "                dist=sum(np.abs(np.array(query)-np.array(neigh)))\n",
    "                if dist<r:\n",
    "                    NN.append(neigh)\n",
    "        return NN\n",
    "    results=sc.parallelize(Tables.value).map(lambda bucket:Nearest_Neighbors(bucket,query,r))\n",
    "    results_LSH=list(map(lambda x:len(x),results.collect()))\n",
    "\n",
    "except:\n",
    "    \n",
    "    sc.stop()\n",
    "    \n",
    "def linear_search():\n",
    "    NN=[]\n",
    "    FP=[]\n",
    "    ANN=[]\n",
    "    for item in data:\n",
    "        dist=sum(np.abs(np.array(query)-np.array(item)))\n",
    "        if dist<r:\n",
    "                NN.append(item)\n",
    "        elif r<=dist<=c*r:\n",
    "                ANN.append(item)\n",
    "        elif dist>=c*r:\n",
    "                FP.append(item)\n",
    "    return [NN,ANN,FP]\n",
    "\n",
    "result_linear_search=linear_search()\n",
    "\n",
    "print('Linear search results:\\nNumber of NN with dist < r: ',len(result_linear_search[0]))\n",
    "print('LSH results:\\nNumber of NN with dist < r: ',sum(results_LSH))\n",
    "\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
