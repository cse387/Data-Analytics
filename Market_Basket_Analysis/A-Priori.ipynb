{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent single itemsets --> 647\n",
      "Number of frequent pair itemsets --> 1334\n",
      "Association for two pair frequent Itemsets Rule with Conf>0.95) [('DAI43868', '--->', 'SNA82528', 0.972972972972973, 0.963455594110557), ('DAI88079', '--->', 'FRO40251', 0.9867256637168141, 0.9721923689674492), ('DAI93865', '--->', 'FRO40251', 1.0, 0.9933121121507347), ('ELE12951', '--->', 'FRO40251', 0.9905660377358491, 0.9871577871972812), ('FRO92469', '--->', 'FRO40251', 0.983510011778563, 0.9562118541630522), ('GRO38636', '--->', 'FRO40251', 0.9906542056074766, 0.9872138017619411), ('GRO85051', '--->', 'FRO40251', 0.999176276771005, 0.9601421621123123)]\n",
      "Triplets ---> [[('ELE17451', 'GRO99222', 'SNA90258')], [('ELE26917', 'ELE52966', 'GRO99222'), ('ELE26917', 'GRO99222', 'SNA30755'), ('ELE17451', 'ELE26917', 'GRO99222'), ('ELE26917', 'GRO99222', 'SNA80192'), ('ELE26917', 'GRO12298', 'GRO99222'), ('ELE26917', 'GRO99222', 'SNA11465'), ('ELE17451', 'GRO99222', 'SNA80192'), ('ELE17451', 'GRO12298', 'GRO99222'), ('ELE17451', 'GRO99222', 'SNA11465'), ('ELE17451', 'ELE52966', 'GRO99222'), ('ELE17451', 'GRO99222', 'SNA30755'), ('ELE17451', 'ELE26917', 'SNA80192'), ('ELE17451', 'ELE26917', 'ELE52966'), ('ELE17451', 'ELE26917', 'SNA30755'), ('ELE17451', 'SNA30755', 'SNA80192')], [('DAI22896', 'ELE17451', 'GRO73461'), ('ELE17451', 'GRO73461', 'SNA99873'), ('ELE17451', 'FRO86643', 'GRO73461'), ('DAI22896', 'ELE17451', 'SNA99873'), ('DAI22896', 'ELE17451', 'FRO86643'), ('ELE17451', 'FRO86643', 'SNA99873'), ('DAI22896', 'GRO73461', 'SNA99873'), ('DAI22896', 'FRO86643', 'GRO73461'), ('FRO86643', 'GRO73461', 'SNA99873')]]\n"
     ]
    }
   ],
   "source": [
    "''' A-Priori Algorithm implemented from the scratch'''\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import findspark\n",
    "import math\n",
    "findspark.init()\n",
    "from pyspark import SparkContext,SparkConf\n",
    "conf=SparkConf()\n",
    "sc = SparkContext(conf=conf )\n",
    "'''\n",
    "array=[0 for i in range(10000)]\n",
    "l=[2]\n",
    "def count(x,l):\n",
    "    s=0\n",
    "    for x in range(1000):\n",
    "        #if x not in l:\n",
    "        s+=l[0]\n",
    "        #else:\n",
    "         #   continue\n",
    "    return s\n",
    "    \n",
    "res=sc.parallelize(array).map(lambda x:count(x,l))\n",
    "print(res.take(3))\n",
    "'''\n",
    "text = sc.textFile(\"browsing.txt\")\n",
    "text=text.map(lambda x:x.strip().split(' '))\n",
    "length=text.count()\n",
    "count=text.flatMap(lambda x:x).map(lambda x:(x,1))\n",
    "freq=count.reduceByKey(lambda x,y:x+y).filter(lambda x:x[1]>=100)\n",
    "print(\"Number of frequent single itemsets -->\",freq.count())\n",
    "countIDs=freq.collectAsMap()#count.countByKey()\n",
    "def create_pairs(x):\n",
    "    temp=[]\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i+1,len(x)):\n",
    "            if x[i] in countIDs.keys() and x[j] in countIDs.keys():\n",
    "                key=tuple(sorted((x[i],x[j])))\n",
    "                temp.append(key)\n",
    "    return temp\n",
    "text=text.map(lambda x:create_pairs(x))\n",
    "\n",
    "count=text.flatMap(lambda x:x).map(lambda x:(x,1))\n",
    "freq=count.reduceByKey(lambda x,y:x+y).filter(lambda x:x[1]>=100)\n",
    "print(\"Number of frequent pair itemsets -->\",freq.count())\n",
    "countIDs1=freq.collectAsMap()#count.countByKey()\n",
    "\n",
    "def compute_pair_confidence(x):\n",
    "    temp=[]\n",
    "    for i in range(len(x[0])):\n",
    "        temp.append(x[1]/countIDs[x[0][i]])\n",
    "    idx=temp.index(max(temp))\n",
    "    ret=(x[0][idx],)\n",
    "    for i in range(len(x[0])):\n",
    "        if i!=idx:\n",
    "            ret+=('--->',x[0][i])\n",
    "    confidence=max(temp)\n",
    "    return ret+(confidence,math.fabs(confidence-countIDs[x[0][idx]]/length))\n",
    "#Compute the Interesting Associations Rules for pair itemsets\n",
    "\n",
    "Association_Rule_1=freq.map(lambda x:compute_pair_confidence(x))\n",
    "print(\"Association for two pair frequent Itemsets Rule with Conf>0.95)\",sorted(Association_Rule_1.filter(lambda x:x[-1]>0.95).take(8)))\n",
    "def create_triplets(l):\n",
    "    temp=[]\n",
    "    for i in range(len(l)):\n",
    "        for j in range(i+1,len(l)):\n",
    "            for z in l[j]:\n",
    "                if z not in l[i]:\n",
    "                    t=tuple(sorted(l[i]+(z,)))\n",
    "                    if t not in temp and l[i] in countIDs1.keys():\n",
    "                        temp.append(t)\n",
    "    i=0\n",
    "    while(i<len(temp)):\n",
    "        flag=True\n",
    "        for j in range(0,len(temp[i])):\n",
    "            for k in range(j+1,len(temp[i])):\n",
    "                if tuple(sorted((temp[i][j],temp[i][k]))) not in l:\n",
    "                    del temp[i]\n",
    "                    flag=False\n",
    "                    break\n",
    "            if flag==False:\n",
    "                i=i-1\n",
    "                break\n",
    "        i+=1\n",
    "    return temp\n",
    "\n",
    "text=text.map(lambda x:create_triplets(x))\n",
    "\n",
    "print(\"Triplets --->\",text.take(3))\n",
    "count=text.flatMap(lambda x:x).map(lambda x:(x,1))\n",
    "freq=count.reduceByKey(lambda x,y:x+y).filter(lambda x:x[1]>=100)\n",
    "print(\"Number of frequent triple itemsets-->\",freq.count())\n",
    "#countIDs2=freq.collectAsMap()#count.countByKey()\n",
    "print(freq.take(3))\n",
    "def compute_triplet_confidence(x):\n",
    "    temp=[]\n",
    "    for i in range(len(x[0])-1):\n",
    "        temp.append(((x[0][i],),countIDs[x[0][i]]))\n",
    "        for j in range(i+1,len(x[0])):\n",
    "                    key=tuple(sorted((x[0][i],x[0][j])))\n",
    "                    temp.append((key,countIDs1[key]))\n",
    "    I,support=min(temp,key=lambda x:x[1])\n",
    "    j=()\n",
    "    for i in x[0]:\n",
    "        if i not in I:\n",
    "            j+=(i,)\n",
    "    confidence=x[1]/support\n",
    "    if len(j)==1:\n",
    "        probability=countIDs[j[0]]/length\n",
    "    else:\n",
    "        probability=countIDs1[j]/length\n",
    "    return I+('--->',j,confidence,math.fabs(confidence-probability))              \n",
    "        \n",
    "Association_Rule_2=freq.map(lambda x:compute_triplet_confidence(x))\n",
    "print(\"Association for three pair frequent Itemsets Rule with Conf>0.55)\",sorted(Association_Rule_2.filter(lambda x:x[-2]>0.55).take(20)))\n",
    "print(Association_Rule_2.take(2))\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
